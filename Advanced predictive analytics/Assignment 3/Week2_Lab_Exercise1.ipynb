{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efcafd1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Downloads\\spark-3.5.0-bin-hadoop3\\python\\pyspark\\sql\\context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary pyspark modules and spark context\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.types import * \n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import col, asc,desc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.mllib.stat import Statistics\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler,StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "spark=SparkSession.builder \\\n",
    ".master (\"local[*]\")\\\n",
    ".appName(\"week2_exercise\")\\\n",
    ".getOrCreate()\n",
    "\n",
    "sc=spark.sparkContext\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceadc8d",
   "metadata": {},
   "source": [
    "## Q1. Use a map function in spark to append \"s\" at end of each of the data elements\n",
    "e.g. Lions, Dolphins, Whales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3b57d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "mammals=[\"Lion\", \"Dolphin\", \"Whale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b76eab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map\n",
      "input rdd:  ['Lion', 'Dolphin', 'Whale']\n",
      "output rdd:  ['Lions', 'Dolphins', 'Whales']\n"
     ]
    }
   ],
   "source": [
    "# Q1 Solution\n",
    "print ('Map')\n",
    "def append_s(x:str) -> str:\n",
    "    return x+\"s\"\n",
    "    \n",
    "rdd = sc.parallelize(mammals)\n",
    "print ('input rdd: ', rdd.take(3))\n",
    "\n",
    "rdd = rdd.map(append_s)\n",
    "print ('output rdd: ', rdd.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8c7ba9",
   "metadata": {},
   "source": [
    "## Q2. Filter all the languages that dont start with F, you can use Spark filter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02215694",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages=[\"spanish\", \"french\", \"farsi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e2e1852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter\n",
      "input rdd:  ['spanish', 'french', 'farsi']\n",
      "output rdd:  ['spanish']\n"
     ]
    }
   ],
   "source": [
    "# Q2 Solution\n",
    "print ('Filter')\n",
    "def filter_by_f(x:str) -> str:\n",
    "    return not x.startswith('f')\n",
    "\n",
    "rdd = sc.parallelize(languages)\n",
    "print ('input rdd: ', rdd.take(3))\n",
    "\n",
    "rdd = rdd.filter(filter_by_f)\n",
    "print ('output rdd: ', rdd.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b898ef",
   "metadata": {},
   "source": [
    "## Q3. Create a list that contains list of both RDDs\n",
    "Output=[\"one\", \"two\",\"a\", \"b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb27a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [\"one\", \"two\"]\n",
    "letters = [\"a\", \"b\"]\n",
    "numbersRDD=sc.parallelize(numbers)\n",
    "lettersRDD=sc.parallelize(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62105c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNION\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['one', 'two', 'a', 'b']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q3 Solution\n",
    "print (\"UNION\")\n",
    "Output = numbersRDD.union(lettersRDD)\n",
    "Output.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e772885e",
   "metadata": {},
   "source": [
    "# Q4. Left outer Join following RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de63db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1=[(\"a\", 1), (\"b\",2), (\"c\",3)]\n",
    "rdd2=[(\"b\", \"second\"), (\"c\",\"third\"), (\"d\",\"fourth\")]\n",
    "pairRdd1 = sc.parallelize(rdd1)\n",
    "pairRdd2 = sc.parallelize(rdd2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "518f410c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'c']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q4 Solution\n",
    "joined = pairRdd1.join(pairRdd2).map(lambda x: (x[0]))\n",
    "joined.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701d241b",
   "metadata": {},
   "source": [
    "# Q5. Order the data by the first name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba2a46ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [Row(First_name=\"John\", Last_name=\"Young\", age=23),\n",
    "Row(First_name=\"Eric\", Last_name=\"Wind\", age=16),\n",
    "Row(First_name=\"Mike\", Last_name=\"Myers\", age=7)]\n",
    "\n",
    "dataRdd=sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf6b7475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(First_name='Eric', Last_name='Wind', age=16),\n",
       " Row(First_name='John', Last_name='Young', age=23),\n",
       " Row(First_name='Mike', Last_name='Myers', age=7)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q5 Solution\n",
    "Ordered = dataRdd.sortBy(lambda x: x[0])\n",
    "Ordered.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
